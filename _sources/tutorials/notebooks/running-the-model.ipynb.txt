{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the model\n",
    "================\n",
    "\n",
    "\n",
    "This note explains in a nutshell how the data should be formatted and what preprocessing steps are needed to run the WATRES model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Check That Your Dataset Has the Right Format\n",
    "\n",
    "\n",
    "Your dataset should be a file named `{site_name}.txt` with the following required column names:\n",
    "\n",
    "- **`t`**: Represents the year in decimal format (e.g., 2022.45).  \n",
    "- **`p`**: Precipitation.  \n",
    "- **`pet`**: Potential evapotranspiration.  \n",
    "- **`q`**: Streamflow.  \n",
    "- **`Cp`**: Input tracer data.  \n",
    "- **`Cq`**: Output tracer data.  \n",
    "\n",
    "---\n",
    "\n",
    "### Folder Structure for Using WATRES\n",
    "\n",
    "To properly use the WATRES package, create a folder for your site named `{site_name}`. This folder should follow the structure below:\n",
    "\n",
    "- WATRES will save the models you train for this site in the same folder.\n",
    "- Two subfolders\n",
    "  - **`data/`**:  \n",
    "    This subfolder stores the data: `{site_name}.txt`.\n",
    "\n",
    "  - **`save/`**:  \n",
    "    WATRES will save the models you train for this site in this folder. This folder will also store the statistics on the results of a trained model, created when calling the `compute_results.py` method (see the `scripts` folder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training a Model\n",
    "\n",
    "### ➡️ Run the Script: `train_models.py`\n",
    "\n",
    "This scripts looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainf(x): \n",
    "    import sys\n",
    "    sys.path.append(os.path.join(path_root))\n",
    "    from WATRES import WATRES\n",
    "    model_bert = WATRES(pathsite=x['pathsite'], site=x['site'], algo=x['algo'], site_name2save=x['site_name2save'])\n",
    "    model_bert.train(BATCH_SIZE=4000, Tmax = 43200, n_validation = 365*24*2, n_train=365*24*10, seed = x['seed'], nb_epochs=400, std_input_noise=x['input_std'], std_output_noise=x['output_std'])\n",
    "    return 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.chdir(os.path.join(path_root, 'WATRES'))\n",
    "\n",
    "    # Define the sites and algorithms\n",
    "    \n",
    "    input_std = 0.1\n",
    "    output_std = 0.1\n",
    "    sites = ['Pully_small_storage', 'Pully_large_storage', 'Lugano_small_storage','Lugano_large_storage','Basel_small_storage','Basel_large_storage'] \n",
    "\n",
    "\n",
    "    algos = ['WATRES']\n",
    "\n",
    "    \n",
    "    settings_algos = []\n",
    "    for site in sites:\n",
    "        pathsite = os.path.join(path_root, f'data/{site}/')\n",
    "        \n",
    "        for algo in algos:\n",
    "            site_name2save = 'input_std_' + str(input_std) + '-output_std_' + str(output_std)\n",
    "\n",
    "            settings_algos.append({\n",
    "                'site': site,\n",
    "                'site_name2save':site_name2save,\n",
    "                'pathsite': pathsite,\n",
    "                'algo': algo,\n",
    "                'seed': 0,\n",
    "                'input_std':input_std,\n",
    "                'output_std':output_std\n",
    "            })\n",
    "\n",
    "    for sett in settings_algos:\n",
    "        trainf(sett)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we explain step by step the meaning of the parameter you can define:\n",
    "\n",
    "- `input_std`: standard deviation of the Gaussian white noise that will be added on the input tracer data before training the model.\n",
    "\n",
    "- `output_std`: standard deviation of the Gaussian white noise that will be added on the output tracer data before training the model.\n",
    "\n",
    "- `sites`: list of the names of the site on which you want to train the model.\n",
    "\n",
    "- `algos`: list of the names of the model you want to use.\n",
    "\n",
    "- `site_name2save`: You can freely decide to give the name you want to the model that you be trained. This name will be used to save the checkpoint and the results.\n",
    "\n",
    "\n",
    "- `model_bert.train(BATCH_SIZE=4000, n_validation = 365*24*2, n_train=365*24*10, seed = x['seed'], nb_epochs=400, std_input_noise=x['input_std'], std_output_noise=x['output_std'])`\n",
    "    - `BATCH_SIZE`: size of the training set. Note that these points will be sampled equally across the four quartiles of the discharge range.\n",
    "    - `Tmax`: age horizon used to model the transit time distributions.\n",
    "    - `n_validation`: number of most recent time points to be withheld from training (e.g., for forecasting).\n",
    "    - `n_train`: number of time steps directly before the validation period to be used for sampling the training data.\n",
    "    - `seed`: random seed\n",
    "    - `nb_epochs`: number of epochs to train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Inference\n",
    "\n",
    "In the following, we explain how inference can be made easily with a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site = 'Pully_small_storage'\n",
    "\n",
    "# Name that you provided to you trained model (TO BE MODIFIED)\n",
    "site_name2save = 'input_std_0.1-output_std_0.1'\n",
    "\n",
    "algo = 'WATRES'\n",
    "\n",
    "\n",
    "# Define the dates for which you would like to get the predicted transit time distributions.\n",
    "def filter_dates(dates):\n",
    "    return np.where(dates>=2020)[0]\n",
    "\n",
    "\n",
    "x = {\n",
    "    'pathsite': os.path.join(root_path, f\"data/{site}/\"),\n",
    "    'path_model': os.path.join(root_path, f\"data/{site}/save/save_{site_name2save}_{algo}.pth.tar\"),\n",
    "    'site': site,\n",
    "    'algo': algo\n",
    "}\n",
    "\n",
    "# Loading the pretrained model\n",
    "model = WATRES(pathsite=x['pathsite'], site=x['site'], algo=x['algo'], path_model=x['path_model'])\n",
    "\n",
    "# Getting the results for the dates defined by the filter\n",
    "results = model.model_estimate(filter_dates, BATCH_SIZE=400)\n",
    "\n",
    "# Showing prediction on output tracer data\n",
    "dates = results['timeyear']\n",
    "\n",
    "# Observed output tracer\n",
    "Cout = results['Cout']\n",
    "\n",
    "# Predicted output tracer\n",
    "Chat = results['Chat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Computing automatically some relevant statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if you want, you can also run the Script: `compute_results.py`.\n",
    "\n",
    "Running this script will allow you to precompute a lot of relevant quantities automatically.\n",
    "\n",
    "You can then rely on the notebook `reproducing_figures_paper.ipynb` in the folder `notebook` to get nice visualizations similar to the ones produced in our paper.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
